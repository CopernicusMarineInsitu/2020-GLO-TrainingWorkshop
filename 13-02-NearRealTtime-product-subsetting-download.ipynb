{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![header](https://i.imgur.com/I4ake6d.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IN SITU GLOBAL SEAS TRAINING\n",
    "<div style=\"text-align: right\"><i> 13-02-Part-two-out-of-five </i></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# GLO `NRT` Product/dataset Subsetting & Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**General Note 1**: Execute each cell through the <button class=\"btn btn-default btn-xs\"><i class=\"icon-play fa fa-play\"></i></button> button from the top MENU (or keyboard shortcut `Shift` + `Enter`).<br>\n",
    "<br>\n",
    "**General Note 2**: If, for any reason, the kernel is not working anymore, in the top MENU, click on the <button class=\"btn btn-default btn-xs\"><i class=\"fa fa-repeat icon-repeat\"></i></button> button. Then, in the top MENU, click on \"Cell\" and select \"Run All Above Selected Cell\".<br>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\">\n",
    "    <ul class=\"toc-item\">\n",
    "        <li><span><a href=\"#1.-Introduction\" data-toc-modified-id=\"1.-Introduction\">1. Introduction</a></span></li>\n",
    "        <li>\n",
    "            <span><a href=\"#2.-Setup\" data-toc-modified-id=\"2.-Setup\">2. Setup</a></span>\n",
    "            <ul>\n",
    "                 <li><span><a href=\"#2.1.-Python-packages\" data-toc-modified-id=\"2.1.-Python-packages\">2.1. Python packages</a></span></li>\n",
    "               <li><span><a href=\"#2.2.-Auxiliary-functions\" data-toc-modified-id=\"2.2-Setup\">2.2. Auxiliary functions</a></span></li>\n",
    "                <li><span><a href=\"#2.3.-Copernicus-Database\" data-toc-modified-id=\"2.3.-Copernicus-Database\">2.3. Copernicus database</a></span></li>\n",
    "               <li><span><a href=\"#2.4.-Target-area\" data-toc-modified-id=\"2.4-Target-area\">2.4. Target area</a></span></li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><span><a href=\"#3.-Getting-started\" data-toc-modified-id=\"3.-Getting-started\">3. Getting started</a></span></li>\n",
    "        <li><span><a href=\"#4.-Operations\" data-toc-modified-id=\"4.-Operations\">4. Operations</a></span>\n",
    "        <ul>\n",
    "            <li>\n",
    "            <span><a href=\"#4.1.-Subsetting\" data-toc-modified-id=\"4.1.-Subsetting\">4.1. Subsetting</a></span>\n",
    "            <ul>\n",
    "                <li><span><a href=\"#4.1.1.-By-collection\" data-toc-modified-id=\"4.1.1.-By-collection\">4.1.1. By collection</a></span></li>\n",
    "                <li><span><a href=\"#4.1.2.-By-time-range\" data-toc-modified-id=\"4.1.2.-By-time-range\">4.1.2. By time range</a></span></li>\n",
    "                <li><span><a href=\"#4.1.3.-By-bounding-box\" data-toc-modified-id=\"4.1.3.-By-bounding-box\">4.1.3. By bounding-box</a></span></li>\n",
    "                <li><span><a href=\"#4.1.4.-By-last-position\" data-toc-modified-id=\"4.1.4.-By-last-position\">4.1.4. By last position</a></span></li>\n",
    "                <li><span><a href=\"#4.1.5.-By-data-type\" data-toc-modified-id=\"4.1.5.-By-data-type\">4.1.5. By data type</a></span></li>\n",
    "                <li><span><a href=\"#4.1.6.-By-file-type\" data-toc-modified-id=\"4.1.6.-By-file-type\">4.1.6. By file type</a></span></li>\n",
    "                <li><span><a href=\"#4.1.7.-By-parameter\" data-toc-modified-id=\"4.1.7.-By-parameter\">4.1.7. By parameter</a></span></li>\n",
    "                <li><span><a href=\"#4.1.8.-By-platform-code\" data-toc-modified-id=\"4.1.8.-By-platform-code\">4.1.8. By platform code</a></span></li>\n",
    "                <li><span><a href=\"#4.1.9.-By-provider\" data-toc-modified-id=\"4.1.9.-By-provider\">4.1.9. By provider</a></span></li>\n",
    "                <li><span><a href=\"#4.1.10.-Subsetting-by-several-criterias-at-once\" data-toc-modified-id=\"4.1.10.-Subsetting-by-several-criterias-at-once\">4.1.10. By several criterias at once</a></span></li>\n",
    "            </ul>\n",
    "            </li>\n",
    "            <li><span><a href=\"#4.2.-Exporting\" data-toc-modified-id=\"4.2.-Exporting\">4.2. Exporting</a></span></li>\n",
    "            <li><span><a href=\"#4.3.-Downloading\" data-toc-modified-id=\"4.3.-Downloading\">4.3. Downloading</a></span></li>          \n",
    "        </ul>\n",
    "        </li>\n",
    "        <li><span><a href=\"#5.-Wrap-up\" data-toc-modified-id=\"5.-Wrap-up\">5. Wrap-up</a></span></li>\n",
    "        <li><span><a href=\"#6.-Next-Tutorial\" data-toc-modified-id=\"6.-Next-Tutorial\">6. Next tutorial</a></span></li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction \n",
    "[Go back to the \"Table of Contents\"](#Table-of-Contents)\n",
    "\n",
    "This notebook focus on getting an overview of the files available in the different collections (`latest`, `monthly` and `history`) available within the In Situ Near Real Time product/dataset covering the Global Seas: `INSITU_GLO_NRT_OBSERVATIONS_013_030`. Click [here](https://resources.marine.copernicus.eu/?option=com_csw&task=results?option=com_csw&view=details&product_id=INSITU_GLO_NRT_OBSERVATIONS_013_030) to  view the dedicated section of this product within the [CMEMS Catalog](http://marine.copernicus.eu/services-portfolio/access-to-products/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any In Situ NRT product/dataset is just a bunch of netcdf files produced by the platforms (*drifters, profilers, gliders, moorings, HF-radars, vessels etc*) deployed in a certain seas (in this case, the Global Seas); so many files that navigation/subsetting can be challenging. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| ![glo.gif](img/glo.png)| \n",
    "|:--:| \n",
    "| *Snapshot of the last location (point or trajectory) of the platforms providing near real time data in the GLO area in the last 30 days* |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To smooth the process of data discovery to users, the In Situ TAC provides a set of `index files` that describe the aforementioned netCDF collections. In addition to these index files, it is also possible to find further info regarding each platform contributting with files on the `index_platform.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Index |  Description |\n",
    "| ------- | ----------- |\n",
    "| `index_latest.txt`  |  List of available files within the latest collection + metadata | \n",
    "| `index_monthly.txt`   | List of available files within the monthly collection + metadata |\n",
    "| `index_history.txt`   |  List of available files within the history collection + metadata |\n",
    "| `index_platform.txt`   | Full list of platforms + metadata |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check more about these files in the <a href=\"https://archimer.ifremer.fr/doc/00324/43494/\" target=\"_blank\">Product User Manual</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>OBJECTIVE</b>\n",
    "    \n",
    "***  \n",
    "To select and download only those netCDFs matching our needs from the whole original set of files that composes the GLO NRT product/dataset by using the aforementioned index files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup\n",
    "[Go back to the \"Table of Contents\"](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the notebook to properly run we need to first load the next packages available from the Jupyter Notebook Ecosystem. Please run the `next cell`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import IPython\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "from collections import namedtuple\n",
    "import ftputil\n",
    "from shapely.geometry import box, Point\n",
    "from urllib.parse import urlparse\n",
    "import folium\n",
    "from folium import plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>WARNING</b>\n",
    "    \n",
    "***  \n",
    "If any of them raises any error it means you need to install the module first. For doing so please:\n",
    "1. Open a new cell in the notebook\n",
    "2. Run <i>`!conda install packageName --yes`</i> or <i>`!conda install -c conda-forge packageName --yes`</i> or <i>`!pip install packageName`</i>\n",
    "3. Import again!\n",
    "<br><br>\n",
    "Example: <i>how-to-solve import error for json2html module </i>\n",
    "\n",
    "![errorImporting.gif](img/errorImporting.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Auxiliary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the product we are going to analyse covers all the world oceans, we will better focus on a specific area of interest.<br>\n",
    "Next function (declared with `def ...`) will allow us to reach only the information linked to a given area or time range.<br>Please run the next cell so that the notebook load it in memory for later use:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul><li id=\"TemporalOverlap\"><i>Time-Overlap</i> function definition</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeOverlap(row, targeted_range):\n",
    "    # Checks if a file contains data in the specified time range (targeted_range)\n",
    "    result = False\n",
    "    try:\n",
    "        date_format = \"%Y-%m-%dT%H:%M:%SZ\"\n",
    "        targeted_ini = datetime.datetime.strptime(targeted_range.split('/')[0], date_format)\n",
    "        targeted_end = datetime.datetime.strptime(targeted_range.split('/')[1], date_format)\n",
    "        time_start = datetime.datetime.strptime(row['time_coverage_start'],date_format)\n",
    "        time_end = datetime.datetime.strptime(row['time_coverage_end'],date_format)\n",
    "        Range = namedtuple('Range', ['start', 'end'])\n",
    "        r1 = Range(start=targeted_ini, end=targeted_end)\n",
    "        r2 = Range(start=time_start, end=time_end)\n",
    "        latest_start = max(r1.start, r2.start)\n",
    "        earliest_end = min(r1.end, r2.end)\n",
    "        delta = (earliest_end - latest_start).days + 1\n",
    "        overlap = max(0, delta)\n",
    "        if overlap != 0:\n",
    "            result = True\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul><li id=\"SpatialOverlap\"><i>Spatial-Overlap</i> function definition</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatialOverlap(row, targeted_bbox):\n",
    "    # Checks if a file contains data in the specified area (targeted_bbox)\n",
    "    result = False\n",
    "    try:\n",
    "        geospatial_lat_min = float(row['geospatial_lat_min'])\n",
    "        geospatial_lat_max = float(row['geospatial_lat_max'])\n",
    "        geospatial_lon_min = float(row['geospatial_lon_min'])\n",
    "        geospatial_lon_max = float(row['geospatial_lon_max'])\n",
    "        targeted_bounding_box = box(targeted_bbox[0], targeted_bbox[1],targeted_bbox[2], targeted_bbox[3])\n",
    "        bounding_box = box(geospatial_lon_min, geospatial_lat_min,geospatial_lon_max, geospatial_lat_max)\n",
    "        if targeted_bounding_box.intersects(bounding_box):  # check other rules on https://shapely.readthedocs.io/en/stable/manual.html\n",
    "            result = True\n",
    "    except Eception as e:\n",
    "        pass\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul><li id=\"LocationInRange\"><i>LocationInRange</i> function definition</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lastLocationInRange(row, targeted_bbox):\n",
    "    # Checks if a file has been produced by a platform whose last position is within the specified area (targeted_bbox)\n",
    "    result = False\n",
    "    try:\n",
    "        geospatial_lat = float(row['last_latitude_observation'])\n",
    "        geospatial_lon = float(row['last_longitude_observation'])\n",
    "        targeted_bounding_box = box(targeted_bbox[0], targeted_bbox[1],targeted_bbox[2], targeted_bbox[3])\n",
    "        location = Point(geospatial_lon, geospatial_lat)\n",
    "        if targeted_bounding_box.contains(location):#check other rules on https://shapely.readthedocs.io/en/stable/manual.html\n",
    "            result = True\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For exploring the product/dataset we will use a set of files called `index files` located in the CMEMS FTP server. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Download the index files**.\n",
    "In order to download the most updated version of these files we will use the next function. <br>Please `run the next cell` to load it (te funtion) in memory for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndexFiles(usr,pas,dataset):\n",
    "    #Provides the index files available at the ftp server\n",
    "    indexes = dataset['index_files'] + [dataset['index_platform']]\n",
    "    with ftputil.FTPHost(dataset['host'], usr, pas) as ftp_host:  # connect to CMEMS FTP\n",
    "        for index in indexes:\n",
    "            remotefile= \"/\".join(['Core',dataset['product'],dataset['name'],index])\n",
    "            print('.....Downloading ' + index)\n",
    "            localfile = os.path.join(os.getcwd(),'data','index_files',index)\n",
    "            ftp_host.download(remotefile,localfile)  # remote, local\n",
    "    print('Ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Index files reader**.\n",
    "In order to load the information contained in *each* of the files we will use the next function. <br>Please `run the next cell` to load it in memory for later use: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readIndexFileFromCWD(path2file, targeted_bbox):\n",
    "    #Load as pandas dataframe the file in the provided path\n",
    "    filename = os.path.basename(path2file)\n",
    "    print('...Loading info from: '+filename)\n",
    "    if targeted_bbox != None:\n",
    "        raw_index_info =[]\n",
    "        chunks = pd.read_csv(path2file, skiprows=5,chunksize=1000)\n",
    "        for chunk in chunks:\n",
    "            chunk['spatialOverlap'] = chunk.apply(spatialOverlap,targeted_bbox=targeted_bbox,axis=1)\n",
    "            raw_index_info.append(chunk[chunk['spatialOverlap'] == True])\n",
    "        return pd.concat(raw_index_info)\n",
    "    else:\n",
    "        result = pd.read_csv(path2file, skiprows=5)\n",
    "        try:\n",
    "            result = result.rename(columns={\"provider_edmo_code\": \"institution_edmo_code\"})\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Index files merger**.\n",
    "In order to load the information contained in *all* the indexes in a one single entity we will use the next function. <br>Please `run the next cell` to load it in memory for later use: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndexFilesInfo(usr, pas, dataset, targeted_bbox):\n",
    "    # Load and merge in a single entity all the information contained on each file descriptor of a given dataset\n",
    "    # 1) Loading the index platform info as dataframe\n",
    "    path2file = os.path.join(os.path.join(os.path.join(os.getcwd(),'data'), 'index_files'), dataset['index_platform'])\n",
    "    indexPlatform = readIndexFileFromCWD(path2file, None)\n",
    "    indexPlatform.rename(columns={indexPlatform.columns[0]: \"platform_code\" }, inplace = True)\n",
    "    indexPlatform = indexPlatform.drop_duplicates(subset='platform_code', keep=\"first\")\n",
    "    # 2) Loading the index files info as dataframes\n",
    "    netcdf_collections = []\n",
    "    for filename in dataset['index_files']:\n",
    "        path2file = os.path.join(os.getcwd(),'data', 'index_files',filename)\n",
    "        indexFile = readIndexFileFromCWD(path2file, targeted_bbox)\n",
    "        netcdf_collections.append(indexFile)\n",
    "    netcdf_collections = pd.concat(netcdf_collections)\n",
    "    # 3) creating new columns: derived info\n",
    "    netcdf_collections['netcdf'] = netcdf_collections['file_name'].str.split('/').str[-1]\n",
    "    netcdf_collections['file_type'] = netcdf_collections['netcdf'].str.split('.').str[0].str.split('_').str[1]\n",
    "    netcdf_collections['data_type'] = netcdf_collections['netcdf'].str.split('.').str[0].str.split('_').str[2]\n",
    "    netcdf_collections['platform_code'] = netcdf_collections['netcdf'].str.split('.').str[0].str.split('_').str[3]\n",
    "    # 4) Merging the information of all files\n",
    "    headers = ['platform_code','wmo_platform_code', 'institution_edmo_code', 'last_latitude_observation', 'last_longitude_observation','last_date_observation']\n",
    "    result = pd.merge(netcdf_collections,indexPlatform[headers],on='platform_code')\n",
    "    print('Ready!')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Copernicus Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please `set next your CMEMS User credentials` in the next cell and `run the cell` afterwards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr = 'inputHereYourCMEMSUser'\n",
    "pas = 'inputHereYourCMEMSPassword'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>WARNING</b>\n",
    "    \n",
    "***  \n",
    "**Don't you have credentials yet?** <br>Please go [here](https://resources.marine.copernicus.eu/?option=com_sla) to get the above credentials to be able to access CMEMS secured FTP server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated before, we will focus on the Near Real Time product/dataset covering the Global seas so, please `run the next` to load the info defining such product/dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'host': 'nrt.cmems-du.eu',#ftp host => nrt.cmems-du.eu for Near Real Time products\n",
    "    'product': 'INSITU_GLO_NRT_OBSERVATIONS_013_030',#name of the In Situ Near Real Time product in the GLO area\n",
    "    'name': 'glo_multiparameter_nrt',#name of the dataset available in the above In Situ Near Real Time product\n",
    "    'index_files': ['index_latest.txt', 'index_monthly.txt', 'index_history.txt'],#files describing the content of the lastest, monthly and history netCDF file collections available withint he above dataset\n",
    "    'index_platform': 'index_platform.txt',#files describing the netwotk of platforms contributting with files in the abve collections\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TIP</b>\n",
    "    \n",
    "***  \n",
    "In case you want to explore any other In Situ NRT product/dataset just set the above definitions accordingly and you will be able to reproduce the subsetting and downloading we will perform next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Target area\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the product we are going to analyse covers all the world oceans, let's narrow down it a little bit by defining an area of interest. This way you would be able to explore just the data available in a specific region nearby your country for example!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set next a bounding box of interest int he next cell and `run it`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeted_geospatial_lat_min = -20.0  # enter min latitude of your bounding box\n",
    "targeted_geospatial_lat_max = 30.0  # enter max latitude of your bounding box\n",
    "targeted_geospatial_lon_min = -35.0 # enter min longitude of your bounding box\n",
    "targeted_geospatial_lon_max = 20.0 # enter max longitude of your bounding box\n",
    "targeted_bbox = [targeted_geospatial_lon_min, targeted_geospatial_lat_min, targeted_geospatial_lon_max, targeted_geospatial_lat_max]  # (minx, miny, maxx, maxy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see it on a map: `run the next cell`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[53.0, 0], zoom_start=4)\n",
    "upper_left = [targeted_geospatial_lat_max, targeted_geospatial_lon_min]\n",
    "upper_right = [targeted_geospatial_lat_max, targeted_geospatial_lon_max]\n",
    "lower_right = [targeted_geospatial_lat_min, targeted_geospatial_lon_max]\n",
    "lower_left = [targeted_geospatial_lat_min, targeted_geospatial_lon_min]\n",
    "edges = [upper_left, upper_right, lower_right, lower_left]\n",
    "polygon = folium.vector_layers.Polygon(locations=edges)\n",
    "m.add_child(polygon)\n",
    "m.fit_bounds(polygon.get_bounds())\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"margin-left: 2em\">\n",
    "<b>Warning</b>\n",
    "    \n",
    "***  \n",
    "If you do not see any map when running the next cell please change your navigator (try chrome!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Getting started\n",
    "[Go back to the \"Table of Contents\"](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the subsetting to be carried out we need the most recent version of the index files. Please `Run the next cell` to download the index files:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download again the index files. `Run the next cell` to download the index files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getIndexFiles(usr,pas,dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load now the info contained in such files by `running the next cell!`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = getIndexFilesInfo(usr, pas, dataset, targeted_bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Run now the next cell` to see the information just loaded above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important fields in the above info is the `file_name`. This filed contains the full path to the file in the FTP server, saving users from having to know the actual FTP structure. As the above preview does not render such field completely, let's see the first file full path: `Run he next cell`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['file_name'].tolist()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the path into the browser....the file will download straightaway!<br>\n",
    "Next we will aim:\n",
    "<ul><li>the `file_name` field (file path) for downloading operations</li>\n",
    "    <li> the other fileds (file metadata) for the subsetting operations</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Operations\n",
    "[Go back to the \"Table of Contents\"](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Subsetting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to <i>download</i> we need to select only those netCDF files that are of our interest.<br>There are many different criterias (if files contain a certain parameter, if they covers a certain area or/and a specific time range....).<br>Next we will see some examples!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1. By collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select only the files that belongs to one specific collection!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>IMPORTANT</b>\n",
    "\n",
    "***\n",
    "Please remember available options:\n",
    "<ul>\n",
    "    <li><i>latest</i>: daily files from platforms (last 30 days of data)</li>\n",
    "    <li><i>monthly</i>: monthly files from platforms (last 5 years of data)</li>\n",
    "    <li><i>history</i>: one file per platform (all platform data)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Set one collecion` next and `run the cells`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeted_collection = 'monthly' #try 'latest', 'monthly' or 'history'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = info['file_name'].str.contains(targeted_collection)\n",
    "subset = info[condition]\n",
    "subset.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"\">\n",
    "<b>TIP</b>\n",
    "    \n",
    "***  \n",
    "To check if the above output only list the files coming from a certain collection (the one set as targeted_collection') just check the `netcdf` column\n",
    "<ul><li>'latest' timestamp: netcdf file name ends with a YYYYMMDD</li></ul>\n",
    "<ul><li>'monthly' timestamp: netcdf file name ends with a YYYYMM</li></ul>\n",
    "<ul><li>'history' timestamp: netcdf file name ends with a YYYY or none timestamp</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2. By time range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select only the files containing data within the next range of dates. <br>Please `set the start/end dates` you are interested in `and run the cells bellow`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeted_range = '2000-01-01T00:00:00Z/2021-01-01T23:59:59Z' #set your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['timeOverlap'] = info.apply(timeOverlap,targeted_range=targeted_range,axis=1)\n",
    "condition = info['timeOverlap'] == True\n",
    "subset = info[condition]\n",
    "subset.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TIP</b>\n",
    "    \n",
    "***  \n",
    "To check if the above output only list the files containing data within a certain time range (the one set as 'targeted_range') just check `time_coverage_start` and `time_coverage_end` columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3. By bounding-box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look for files containing data from a smaller area within the already established targeted area (see [above](#2.4.-Target-area))<br>`Please set your own area limits` next `and run the cell`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeted_geospatial_lat_min = 30.0  # enter min latitude of your bounding box\n",
    "targeted_geospatial_lat_max = 26.5  # enter max latitude of your bounding box\n",
    "targeted_geospatial_lon_min = -18.5  # enter min longitude of your bounding box\n",
    "targeted_geospatial_lon_max = -13.0  # enter max longitude of your bounding box\n",
    "targeted_bbox = [targeted_geospatial_lon_min, targeted_geospatial_lat_min, targeted_geospatial_lon_max, targeted_geospatial_lat_max]  # (minx, miny, maxx, maxy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the area you have set before: `run the next cell`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[39.0, 0], zoom_start=4)\n",
    "upper_left = [targeted_geospatial_lat_max, targeted_geospatial_lon_min]\n",
    "upper_right = [targeted_geospatial_lat_max, targeted_geospatial_lon_max]\n",
    "lower_right = [targeted_geospatial_lat_min, targeted_geospatial_lon_max]\n",
    "lower_left = [targeted_geospatial_lat_min, targeted_geospatial_lon_min]\n",
    "edges_ = [upper_left, upper_right, lower_right, lower_left]\n",
    "m.add_child(folium.vector_layers.Polygon(locations=edges_))\n",
    "#Zooming closer\n",
    "m.fit_bounds(edges_, max_zoom=5)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>WARNING</b>\n",
    "    \n",
    "***  \n",
    "If you do not see any map when running the next cell please change your navigator (try chrome!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Run the next cell` to obtain the subset of files with data in such area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "info['spatialOverlap'] = info.apply(spatialOverlap,targeted_bbox=targeted_bbox,axis=1)\n",
    "condition = info['spatialOverlap'] == True\n",
    "subset = info[condition]\n",
    "subset.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check now if the bbox of the above files truely overlaps with the targeted area!: `run the next cells`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfFiles = 300 #we will check just a sample of files not all as there might be too many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[39.0, 0], zoom_start=6)\n",
    "m.add_child(folium.vector_layers.Polygon(locations=edges_))\n",
    "for platform, files in subset[:numberOfFiles].groupby(['platform_code', 'data_type']):\n",
    "    color = \"%06x\" % random.randint(0, 0xFFFFFF)\n",
    "    for i in range(0, len(files)):\n",
    "        netcdf = files.iloc[i]['file_name'].split('/')[-1]\n",
    "        upper_left = [\n",
    "            files.iloc[i]['geospatial_lat_max'],\n",
    "            files.iloc[i]['geospatial_lon_min']\n",
    "        ]\n",
    "        upper_right = [\n",
    "            files.iloc[i]['geospatial_lat_max'],\n",
    "            files.iloc[i]['geospatial_lon_max']\n",
    "        ]\n",
    "        lower_right = [\n",
    "            files.iloc[i]['geospatial_lat_min'],\n",
    "            files.iloc[i]['geospatial_lon_max']\n",
    "        ]\n",
    "        lower_left = [\n",
    "            files.iloc[i]['geospatial_lat_min'],\n",
    "            files.iloc[i]['geospatial_lon_min']\n",
    "        ]\n",
    "        edges = [upper_left, upper_right, lower_right, lower_left]\n",
    "        popup_info = '<b>netcdf</b>: ' + files.iloc[i]['netcdf']\n",
    "        m.add_child(folium.vector_layers.Polygon(locations=edges,color='#' + color,popup=(folium.Popup(popup_info))))\n",
    "        m.fit_bounds(edges, max_zoom=6)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>WARNING</b>\n",
    "    \n",
    "***  \n",
    "If you do not see any map when running the next cell please change your navigator (try chrome!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TIP</b>\n",
    "    \n",
    "***  \n",
    "To check if everything went well, just check if the files box is indeed at some point within the one you were interested in (targeted bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>IMPORTANT</b>\n",
    "    \n",
    "***  \n",
    "If you are not satisfied with the resulting output (i.e you want to get only the files whose bbox is completely within the targeted area) please revisit the [definition of the SpatialOverlap](#SpatialOverlap) function and replace the rule applied (`intersects`) by any of the available ones [here](https://shapely.readthedocs.io/en/stable/manual.html#binary-predicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.4. By last position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look for files produced by a platform whose last position is within a smaller area within the already established target area (see [above](#2.4.-Target-area)).<br>`Please set your own area limits` next `and run the cell`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the area you have set before: `run the next cell`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeted_geospatial_lat_min = 10.0  # enter min latitude of your bounding box\n",
    "targeted_geospatial_lat_max = 16.5  # enter max latitude of your bounding box\n",
    "targeted_geospatial_lon_min = -18.5  # enter min longitude of your bounding box\n",
    "targeted_geospatial_lon_max = -13.0  # enter max longitude of your bounding box\n",
    "targeted_bbox = [targeted_geospatial_lon_min, targeted_geospatial_lat_min, targeted_geospatial_lon_max, targeted_geospatial_lat_max]  # (minx, miny, maxx, maxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[39.0, 0], zoom_start=4)\n",
    "upper_left = [targeted_geospatial_lat_max, targeted_geospatial_lon_min]\n",
    "upper_right = [targeted_geospatial_lat_max, targeted_geospatial_lon_max]\n",
    "lower_right = [targeted_geospatial_lat_min, targeted_geospatial_lon_max]\n",
    "lower_left = [targeted_geospatial_lat_min, targeted_geospatial_lon_min]\n",
    "edges_ = [upper_left, upper_right, lower_right, lower_left]\n",
    "m.add_child(folium.vector_layers.Polygon(locations=edges_))\n",
    "#Zooming closer\n",
    "m.fit_bounds(edges_, max_zoom=5)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>WARNING</b>\n",
    "    \n",
    "***  \n",
    "If you do not see any map when running the next cell please change your navigator (try chrome!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Run the next cell` to obtain the subset of files with data in such area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['lastLocationInRange'] = info.apply(lastLocationInRange,targeted_bbox=targeted_bbox,axis=1)\n",
    "condition = info['lastLocationInRange'] == True\n",
    "subset = info[condition]\n",
    "subset.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check now if the bbox of the above files truely overlaps with the targeted area!: `run the next cells`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfFiles = 177 #we will check just a sample of files not all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[39.3, 0], zoom_start=5)\n",
    "m.add_child(folium.vector_layers.Polygon(locations=edges_))\n",
    "for platform, files in subset[:numberOfFiles].groupby(['platform_code', 'data_type']):\n",
    "    color = \"%06x\" % random.randint(0, 0xFFFFFF)\n",
    "    #Last reported position to map as marker\n",
    "    i = len(files)-1\n",
    "    m.add_child(folium.Marker([files.iloc[i]['last_latitude_observation'], files.iloc[i]['last_longitude_observation']], popup=files.iloc[i]['platform_code']+' last position' ))\n",
    "#Zooming closer\n",
    "m.fit_bounds(edges, max_zoom=8)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>WARNING</b>\n",
    "    \n",
    "***  \n",
    "If you do not see any map when running the next cell please change your navigator (try chrome!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TIP</b>\n",
    "    \n",
    "***  \n",
    "To check if everything went well, just check if the markers (last platform position) is indeed within the one you were interested in (targeted bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>IMPORTANT</b>\n",
    "    \n",
    "***  \n",
    "If you are not satisfied with the resulting output please revisit the [definition of the lastLocationInRange](#LocationInRange) function and replace the rule applied (`contains`) by any of the available ones [here](https://shapely.readthedocs.io/en/stable/manual.html#binary-predicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.5. By data type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look for files produced by a certain data type.<br>`Please set a data type` next `and run the cell`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeted_data_type = 'PF' # try others: TG for Tide Gauges, PF for profilers etc =>Product User Manual: https://archimer.ifremer.fr/doc/00324/43494/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Run the next cell` to obtain just the files reported by such data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = info['data_type'] == targeted_data_type\n",
    "subset = info[condition]\n",
    "subset.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TIP</b>\n",
    "    \n",
    "***  \n",
    "To check if the subset only contains the aimed data type (targeted_data_type) just check the `data_type` column of the above output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.6. By file type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look for certain types of files.<br>`Please set a file type` next `and run the cell`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeted_file_type = 'TS' # try others: RV for HF Radar radial velocities...=>Product User Manual: https://archimer.ifremer.fr/doc/00324/43494/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Run the next cell` to obtain just the above type of files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = info['file_type'] == targeted_file_type\n",
    "subset = info[condition]\n",
    "subset.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TIP</b>\n",
    "    \n",
    "***  \n",
    "To check if the subset matches the aimed file type (targeted_file_type) just check the `file_type` column of the above output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.7. By parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look for files containing a certain parameter.<br>`Please set a parameter code` next `and run the cell`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeted_parameter = 'CPHL' #try others: TEMP, SLEV etc => In Situ parameter list: https://archimer.ifremer.fr/doc/00422/53381/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to obtain just the files reporting such parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = info['parameters'].str.contains(targeted_parameter)\n",
    "subset = info[condition]\n",
    "subset.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TIP</b>\n",
    "    \n",
    "***  \n",
    "To check if the subset only contains the aimed parameter (targeted_parameter) just check the `parameters` column of the above output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.8. By platform code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look for files produced by a certain platform.<br>`Please set a platform code` next `and run the cell`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeted_platform_code = 'FuerteventuraTG'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to obtain just the files reported by such platform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = info['platform_code']==targeted_platform_code\n",
    "subset = info[condition]\n",
    "subset.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TIP</b>\n",
    "    \n",
    "***  \n",
    "To check if the subset matches the aimed platform (targeted_platform_code) just check the `platform_code` column of the above output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.9. By provider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look for files produced by a certain provider (find others at: [SeaDataNet](https://edmo.seadatanet.org/search)).<br>`Please set a provider code` next `and run the cell`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeted_provider_code = '1799'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to obtain just the files reported by such provider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['institution_edmo_code'] = ' '+info['institution_edmo_code']+' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = info['institution_edmo_code'].str.contains(targeted_provider_code, na=False)\n",
    "subset = info[condition]\n",
    "subset.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TIP</b>\n",
    "    \n",
    "***  \n",
    "To check if the subset matches the aimed provider (targeted_provider_code) just check the `insitution_edmo_code` column of the above output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.10. Subsetting by several criterias at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the collection of interest, range of time and bbox to find only the files that matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeted_collection = 'history'\n",
    "targeted_range = '2009-01-01T00:00:00Z/2020-12-01T23:59:59Z'\n",
    "targeted_parameter = 'CPHL'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to apply yhe above filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['timeOverlap'] = info.apply(timeOverlap,targeted_range=targeted_range,axis=1)\n",
    "condition1 = info['timeOverlap'] == True\n",
    "\n",
    "condition2 = info['parameters'].str.contains(targeted_parameter)\n",
    "condition3 = info['file_name'].str.contains(targeted_collection)\n",
    "subset = info[condition1 & condition2 & condition3]\n",
    "subset.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Exporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you just want to export the above table containing ftp link to download each file in subset and some more metadata as csv for sharing it (a lot more compact than sharing the actual files), just run the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.to_csv('subsetOffiles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Downloading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have created your own subset (see above examples about how-to), we will loop over the files in such subset and download each of them from the FTP server thanks to the `file_name` column, field that contains the ftp link to the file.<br> Run the next cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = os.getcwd()# Defaults to the current working directory; change it as you please"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treshold = 8 #Please set a file number maxima to download. \n",
    "#This is just an example and we do not wanna trigger the download of too many files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ftputil.FTPHost(dataset['host'], usr, pas) as ftp_host:  # connect to CMEMS FTP\n",
    "    for i in range(0, len(subset)):\n",
    "        if i<treshold:\n",
    "            filepath = subset.iloc[i]['file_name'].split(dataset['host'])[1]\n",
    "            ncdf_file_name = filepath.split('/')[-1]\n",
    "            if ftp_host.path.isfile(filepath):\n",
    "                print('.....Downloading ' + ncdf_file_name)\n",
    "                cwd = os.getcwd()\n",
    "                os.chdir(output_directory)\n",
    "                try:\n",
    "                    ftp_host.download(filepath, ncdf_file_name)  # remote, local\n",
    "                    print('Done!')\n",
    "                except Exception as e:\n",
    "                    print('error!: FTP download failed ...')\n",
    "                os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TIP</b>\n",
    "    \n",
    "***  \n",
    "To check if the files have been donwloaded just check if you find them in the directory specified as <i>output directory</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>WARNING</b>\n",
    " \n",
    "***  \n",
    "FTP download might be forbidden in the remote server for security reasons. <br>If you experience an error please run this jupyter notebook locally for being able to actually download the files. Steps:\n",
    "1. [Install anaconda](https://www.anaconda.com/distribution/): according to your OS (Windows,Linux,Mac...)\n",
    "2. Navigate to the folder containing the notebooks (.ipynb files)\n",
    "3. Run the following command at the Terminal (Mac/Linux) or Command Prompt (Windows): jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Wrap-up\n",
    "[Go back to the \"Table of Contents\"](#Table-of-Contents)\n",
    "\n",
    "So far you should already know how to subset the product/dataset by several subsetting criterias as well as exporting and downloading the resulting subset of files.<br> `If you don't please ask us! it is the moment!`\n",
    "<br>In the next tutorial we will see how to open and visualize some of the files donwloaded. Ready? Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6. Next Tutorial\n",
    "\n",
    "[Go back to the \"Table of Contents\"](#Table-of-Contents)\n",
    "\n",
    "_Click on one of the hyperlinks below to continue the training_\n",
    "<br>\n",
    "[**13-03-NearRealTime-product-managing-files-tideGauges.ipynb**](13-03-NearRealTime-product-managing-files-tideGauges.ipynb)<br>\n",
    "[**13-04-NearRealTime-product-managing-files-saildrones.ipynb**](13-04-NearRealTime-product-managing-files-saildrones.ipynb)<br>\n",
    "[**13-05-NearRealTime-product-managing-files-gliders.ipynb**](13-05-NearRealTime-product-managing-files-gliders.ipynb)<br>"
   ]
  }
 ],
 "metadata": {
  "finalized": {
   "timestamp": 1572899020604,
   "trusted": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
